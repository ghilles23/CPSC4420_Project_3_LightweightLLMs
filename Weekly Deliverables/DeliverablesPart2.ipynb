{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7dbd50b1-9f40-4d0d-b646-028af566b4f3",
      "metadata": {
        "id": "7dbd50b1-9f40-4d0d-b646-028af566b4f3"
      },
      "source": [
        "# Project 3, Lightweight LLMs – Task 2\n",
        "\n",
        "**Supervisor:** Sayedpedram Haeri Boroujeni  \n",
        "**Course:** CPSC 4420 - Artificial Intelligence  \n",
        "**Assignment:** Task 2  \n",
        "**Deadline:** October 27, 2025  \n",
        "\n",
        "## Contributors\n",
        "- **Samuel Jordan** (Parts 1 & 2)\n",
        "- **Gabriel Hillesheim**  \n",
        "- **Patrick Woods** (Part 3)\n",
        "  \n",
        "---\n",
        "\n",
        "## Table of Contents\n",
        "1. [Quantization Fundamentals (Weights & Activations)](#part-1-quantization-fundamentals-weights--activations)  \n",
        "2. [Run the Base Model (SmolLM-135M)](#part-2-run-the-base-model-smollm-135m)  \n",
        "3. [Implement Weight Quantization (8-bit vs 4-bit)](#part-3-implement-weight-quantization-8-bit-vs-4-bit)  \n",
        "4. [Implement Static KV-Cache Quantization](#part-4-implement-static-kv-cache-quantization)  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fac7dab7-af5e-4a3c-8871-418aad550b79",
      "metadata": {
        "id": "fac7dab7-af5e-4a3c-8871-418aad550b79"
      },
      "source": [
        "## Part 1: Quantization Fundamentals (Weights & Activations)\n",
        "*Implement a simple INT8 quantizer in PyTorch for a fully connected layer. Evaluate accuracy before and after quantization.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a97a10c-f7d4-4903-a2f7-350ca4748959",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a97a10c-f7d4-4903-a2f7-350ca4748959",
        "outputId": "2a1fb5be-a784-4225-9095-e694e14512db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline (FP32) output:\n",
            "tensor([[ 1.2113, -0.2507, -0.1274, -0.8630,  0.7295,  0.9688,  0.5489, -0.2225,\n",
            "          0.4110,  0.2604],\n",
            "        [ 0.5140,  0.2072, -0.1497,  0.4514, -0.3403, -0.2416, -0.1721,  1.0568,\n",
            "         -0.3797, -0.2253]], grad_fn=<SliceBackward0>)\n",
            "\n",
            "Quantized (weights + activations) output:\n",
            "tensor([[ 1.2147, -0.2490, -0.1213, -0.8630,  0.7335,  0.9755,  0.5451, -0.2266,\n",
            "          0.4201,  0.2586],\n",
            "        [ 0.5119,  0.2036, -0.1504,  0.4556, -0.3398, -0.2423, -0.1785,  1.0499,\n",
            "         -0.3842, -0.2216]])\n",
            "\n",
            "Relative mean error: 0.008251\n"
          ]
        }
      ],
      "source": [
        "# Part 1.1: Simple per-tensor int8 quant/dequant for weights and activations\n",
        "\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "\n",
        "# ------------------------------\n",
        "# Quantization: float to int8\n",
        "# ------------------------------\n",
        "def quantize_int8_per_tensor(tensor):\n",
        "    \"\"\"Quantizes a float tensor symmetrically to int8 and returns (quantized_tensor, scale).\"\"\"\n",
        "    max_abs = tensor.abs().max()\n",
        "    scale = (max_abs / 127.0).clamp(min=1e-12)\n",
        "    q = torch.clamp(torch.round(tensor / scale), -127, 127)\n",
        "    return q.to(torch.int8), scale\n",
        "\n",
        "# ------------------------------\n",
        "# Dequantization: int8 to float\n",
        "# ------------------------------\n",
        "def dequantize_int8_per_tensor(q, scale):\n",
        "    \"\"\"Converts quantized int8 tensor back to float using scale.\"\"\"\n",
        "    return q.float() * scale\n",
        "\n",
        "# ------------------------------\n",
        "# Quantized Linear Layer (weights and activations)\n",
        "# ------------------------------\n",
        "class QuantLinear(nn.Module):\n",
        "    \"\"\"\n",
        "    Linear layer with both weights and activations quantized to int8.\n",
        "    Dequantizes them to float before performing the matmul (for clarity in this demo).\n",
        "    \"\"\"\n",
        "    def __init__(self, lin: nn.Linear):\n",
        "        super().__init__()\n",
        "        # Quantize weights once during initialization\n",
        "        qW, w_scale = quantize_int8_per_tensor(lin.weight.data.detach())\n",
        "        self.qweight = nn.Parameter(qW, requires_grad=False)\n",
        "        self.register_buffer(\"w_scale\", w_scale)\n",
        "        # Copy bias (still float)\n",
        "        if lin.bias is not None:\n",
        "            self.bias = nn.Parameter(lin.bias.data.detach().clone(), requires_grad=False)\n",
        "        else:\n",
        "            self.bias = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Quantize activations each forward pass\n",
        "        qx, x_scale = quantize_int8_per_tensor(x)\n",
        "        x_deq = dequantize_int8_per_tensor(qx, x_scale)\n",
        "        # Dequantize weights\n",
        "        W = dequantize_int8_per_tensor(self.qweight, self.w_scale)\n",
        "        # Perform standard linear layer computation\n",
        "        out = F.linear(x_deq, W, self.bias)\n",
        "        return out\n",
        "\n",
        "# ------------------------------\n",
        "# Compare outputs before and after quantization\n",
        "# ------------------------------\n",
        "torch.manual_seed(1)\n",
        "lin = nn.Linear(128, 10)       # baseline FP32 layer\n",
        "x = torch.randn(4, 128)        # small batch (4 samples)\n",
        "\n",
        "ref_out = lin(x)               # baseline FP32 output\n",
        "q_lin = QuantLinear(lin)       # quantized weights + activations\n",
        "quant_out = q_lin(x)\n",
        "\n",
        "# Compute mean relative error between outputs\n",
        "rel_err = (quant_out - ref_out).abs().mean() / ref_out.abs().mean()\n",
        "\n",
        "# ------------------------------\n",
        "# Print results\n",
        "# ------------------------------\n",
        "print(\"Baseline (FP32) output:\")\n",
        "print(ref_out[:2])\n",
        "\n",
        "print(\"\\nQuantized (weights + activations) output:\")\n",
        "print(quant_out[:2])\n",
        "\n",
        "print(f\"\\nRelative mean error: {rel_err.item():.6f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "729465c5-5da3-4861-9bef-1236081bc241",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "729465c5-5da3-4861-9bef-1236081bc241",
        "outputId": "c8a29bf9-3408-4a06-ad49-4235995cd86a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 22.5MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 614kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 5.76MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 9.86MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test accuracy BEFORE quantization: 95.300%\n",
            "Test accuracy AFTER  quantization: 95.330%\n",
            "Accuracy drop: -0.030%\n"
          ]
        }
      ],
      "source": [
        "# Part 1.2: Quick accuracy comparison demo with MNIST\n",
        "\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "device = torch.device(\"cpu\")  # keep CPU to avoid device mismatch with the current QuantLinear\n",
        "torch.manual_seed(1)\n",
        "\n",
        "# Data\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "train_ds = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_ds  = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=256, shuffle=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=512, shuffle=False)\n",
        "\n",
        "# Model (the layer we will quantize is the final classifier)\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)  # we'll quantize THIS one\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "\n",
        "model = MLP().to(device)\n",
        "\n",
        "# Train briefly to get non-trivial accuracy\n",
        "opt = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
        "epochs = 2  # short for demo\n",
        "\n",
        "# ------------------------------\n",
        "# Evaluate model before and after quantization\n",
        "# ------------------------------\n",
        "def evaluate(m):\n",
        "    m.eval()\n",
        "    correct = total = 0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in test_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            logits = m(xb)\n",
        "            pred = logits.argmax(dim=1)\n",
        "            correct += (pred == yb).sum().item()\n",
        "            total += yb.numel()\n",
        "    return correct / total\n",
        "\n",
        "for _ in range(epochs):\n",
        "    model.train()\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        logits = model(xb)\n",
        "        loss = F.cross_entropy(logits, yb)\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "# Evaluate BEFORE quantization\n",
        "acc_before = evaluate(model)\n",
        "\n",
        "# Replace the fully connected layer with our INT8 QuantLinear\n",
        "with torch.no_grad():\n",
        "    model.fc2 = QuantLinear(model.fc2)  # uses our class defined above\n",
        "    model = model.to(device)            # stay on CPU for consistency\n",
        "\n",
        "# Evaluate AFTER quantization\n",
        "acc_after = evaluate(model)\n",
        "\n",
        "# ------------------------------\n",
        "# Print results\n",
        "# ------------------------------\n",
        "print(f\"\\nTest accuracy BEFORE quantization: {acc_before*100:.3f}%\")\n",
        "print(f\"Test accuracy AFTER  quantization: {acc_after*100:.3f}%\")\n",
        "print(f\"Accuracy drop: {(acc_before-acc_after)*100:.3f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b09a69f0-c7f6-492a-a79f-88cdc238973b",
      "metadata": {
        "id": "b09a69f0-c7f6-492a-a79f-88cdc238973b"
      },
      "source": [
        "### Part 1.3: Results\n",
        "The INT8-quantized model performs essentially the same as the original FP32 model. The difference of −0.03 percentage points is statistically insignificant. In fact, the quantized model scored slightly higher, but that’s just normal random variation due to data order, rounding noise, etc., and isn't seen across different random seeds.\n",
        "\n",
        "In this application, INT8 quantization successfully reduces model precision and memory/storage cost without hurting accuracy. This demonstrates that our technique is an effective and safe compression strategy for simple models and datasets like MNIST."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc6a3788-8ed0-43f0-aef9-da1960a57499",
      "metadata": {
        "id": "cc6a3788-8ed0-43f0-aef9-da1960a57499"
      },
      "source": [
        "## Part 2: Run the Base Model (SmolLM-135M)\n",
        "*Load SmolLM-135M, run sample prompts, and record baseline latency and GPU memory usage.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27fe21e8-df51-4969-b637-fa6c0be63c62",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395,
          "referenced_widgets": [
            "33c2fda358f940da93d88054b050229e",
            "c818f2a9ea7d490bbd4deac8c45f3e14",
            "93ded89c39864ba1aee151f1d13aa14e",
            "8cb25e903f3d4f9faa6fbad6508bf2bb",
            "fd3844fbb4b24cd0b3a41b506363df16",
            "4ab46436215f412682dc286471340d1d",
            "605463e55d734c74a3c23fe8e07adf0c",
            "c8f5178d331d464b89dbd47c1206b269",
            "83b1edbd137b4d41906c899c82d8a4a2",
            "7116fdc3ab034b509d7025caac2f7b2e",
            "3dce19f827164711a6e3050327ccf034",
            "c716ad721134481083b8f50c1332e16d",
            "fc0346dabc404d30b3d3009c2d04ade5",
            "fdd492f29c97400f8c813c4869e6c4fb",
            "ef208597411f4cd6bb98f573a40dd2ae",
            "91b52e1fd9db468e8a30b79d33901182",
            "961a3e7931db488f97ea4bc997486446",
            "e4c6d49bfa16453f944885705b8adc05",
            "538a566bfa8c4e2daf976014bcaa752a",
            "cd1d7de2b2cf41b5a2ea8456d9649c23",
            "f7910f05596b45f0ba943ff3ee1c93fd",
            "c946a5bb81a44b198e337f382b5ada08",
            "9ac49eee029a4821bbcce494eb09a176",
            "ba04000c26a34a8c824d14e5f3aace00",
            "596d40cbf4a84b2387b1ff03d54163da",
            "71c2dca71979430299550e2585455269",
            "7a10e21a6b7d4b35bde3f4986134dc41",
            "40cd95702f424061a5e538c4580b0a6f",
            "90e2fdaa5e8344e2b4226d5e5a4cb779",
            "019ddcefd37743a69c00e288bf23980e",
            "3bfc24a533a44760a746d3cc3b89a3aa",
            "3b2ba83922e546bea7ad03139b7cee62",
            "71b701308fcc4e669056c9cd8d1ef946",
            "5e9a53bf690546dc980b96f4e3428134",
            "251cf510a6c24ba89ba3c7555711c6da",
            "261786f2049940b1ad008d8fe42522a1",
            "784cda3ea692469d9ab5e87518fa5127",
            "bd1c4ef5dd264564a7365e855345109c",
            "3d837cc0ccb14df1a23d8c0ccf34a61f",
            "ff06f2af132d4607a8694fd31116bac5",
            "874709a5b447497391b98b5409be5cc6",
            "3f27fd94b7934cf89360e1b1d382a92b",
            "1fb09718e8cf456aa2f6e4c631845d31",
            "d58d20ca113f42be9f41a3ca421d237c",
            "3d3be39910914222ae48435fa48fbc01",
            "933602ed7e734a688060efc101bdbf16",
            "c67050aaae5d4a0fbe779f72b751ffba",
            "efba7a3387a34d649d34e5a5fa58e862",
            "ced04c569fe6488eb0d4f152503e6f67",
            "09e66626b2574cad902cddb7f6bcbbaf",
            "654d5a8cde724df6811e22c612010857",
            "da4976cdb7164fc9a88558bda86d9ac1",
            "20e216b0928741a79b5c436f84399aa2",
            "7f16cc502637445db8d72bdab3c00195",
            "ea20b7c4459c46a09e6151171187de83",
            "f9cfaac283744dfc8352be879fe37d97",
            "33cb5befbd534f8abf75183dc98a6b29",
            "5cd9e4ff39174bc482c72b9c76fe2a01",
            "b092c0351e714934844010f481dd36ef",
            "f4473922d7b9410eb70e1dbf1271332e",
            "848dd186be934a3ead1c2759bcc86dc0",
            "ce0cf19bf802409a8ce5ca9af7808f58",
            "e7c30d6c78064751a8ec3347cb46135c",
            "896de32bbcd24330b470f5658fd406d0",
            "a7fcc364a8cf4d8e95eb555568e23383",
            "56f4d77645fe4e69a0720941fc07d297",
            "0e9e86d786d7484daf6a4bb10315d023",
            "868fa306ad8b4f5387e92bf17811eb58",
            "bdbe33baaf7b479cb7f78774810e7094",
            "cf95a4b6ebce4489997fbed8aaa6ab68",
            "f6a351d66a3c4ca1be83e0b66aac78d6",
            "d6ed7d00f1b44fb790e58241d0f890c2",
            "d53dcb7d9c3d40fc9385c90c3b5be62f",
            "6ced5acc9df5425c986cc2084edc7782",
            "6f23081972984776a6ab15c4595d0a16",
            "911a11cde9ab4b91af602ad33db801b7",
            "3b30e3b26a8740acba2ce1ecf4a20c3c",
            "b898583b943d4e228cb9c5281ba1a4ad",
            "08a3d25dff1945e093f206694e800ad5",
            "4ed66f2141f2483da331d73bbfb5a004",
            "c4cd945d718b46e5bef5f0be29383096",
            "c0abae17d8f74be3ba9c110434b96772",
            "9ef5814a2264472ea0f43a291da0abbe",
            "9b70b2e9969c4cbbb484b33c068683df",
            "7890c2642a114f39aa028e2866262ee1",
            "7bfd0770a86b477a9029dbb17f3a15e1",
            "232746eab675492b9471407ebf17161d",
            "c619e901ac524c038d5f6b344bd94b4c"
          ]
        },
        "id": "27fe21e8-df51-4969-b637-fa6c0be63c62",
        "outputId": "0d5f13a3-86a3-4af2-cafb-1b81a1c39e53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: CPU  |  Precision: torch.float32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33c2fda358f940da93d88054b050229e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c716ad721134481083b8f50c1332e16d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ac49eee029a4821bbcce494eb09a176"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e9a53bf690546dc980b96f4e3428134"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/831 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d3be39910914222ae48435fa48fbc01"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/724 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9cfaac283744dfc8352be879fe37d97"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/538M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e9e86d786d7484daf6a4bb10315d023"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b898583b943d4e228cb9c5281ba1a4ad"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Part 2.1: SmolLM-135M model\n",
        "import time, torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Pick device/precision (CUDA if available)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "dtype  = torch.float16 if device == \"cuda\" else torch.float32\n",
        "print(f\"Using device: {device.upper()}  |  Precision: {dtype}\")\n",
        "\n",
        "# Load model/tokenizer\n",
        "model_id = \"HuggingFaceTB/SmolLM-135M\"\n",
        "tok = AutoTokenizer.from_pretrained(model_id)\n",
        "if tok.pad_token is None:\n",
        "    tok.pad_token = tok.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    dtype=dtype,\n",
        "    device_map=\"auto\" if device == \"cuda\" else None\n",
        ").to(device).eval()\n",
        "\n",
        "def run_prompt(prompt, max_new_tokens=250):\n",
        "    \"\"\"Generate text and measure latency, throughput, and peak GPU memory.\"\"\"\n",
        "    wrapped = f\"### Instruction:\\n{prompt}\\n\\n### Response:\\n\"\n",
        "    inputs = tok(wrapped, return_tensors=\"pt\").to(device)\n",
        "    input_len = inputs[\"input_ids\"].shape[-1]\n",
        "\n",
        "    if device == \"cuda\":\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "    t0 = time.perf_counter()\n",
        "    with torch.inference_mode(), torch.autocast(device_type=device, dtype=dtype):\n",
        "        out = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=False, temperature=1.0, top_p=1.0,\n",
        "            no_repeat_ngram_size=3, repetition_penalty=1.05,\n",
        "            pad_token_id=tok.pad_token_id, eos_token_id=tok.eos_token_id\n",
        "        )\n",
        "    dt = time.perf_counter() - t0\n",
        "\n",
        "    # Decode only new tokens (avoid echoing the prompt)\n",
        "    new_tokens = out[0][input_len:]\n",
        "    text = tok.decode(new_tokens, skip_special_tokens=True).strip()\n",
        "\n",
        "    gen_tokens = int(new_tokens.shape[0])\n",
        "    mem_mb = torch.cuda.max_memory_allocated() / (1024**2) if device == \"cuda\" else 0.0\n",
        "\n",
        "    return {\"prompt\": prompt, \"latency_s\": dt, \"gpu_mem_MB\": mem_mb, \"output\": text}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "458eaa3c-2ec4-4e5c-b324-aec5e1e3b4a2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "458eaa3c-2ec4-4e5c-b324-aec5e1e3b4a2",
        "outputId": "efa14fd6-0374-42b5-a6b8-2738c8cbf8a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/amp/autocast_mode.py:283: UserWarning: In CPU autocast, but the target dtype is not supported. Disabling autocast.\n",
            "CPU Autocast only supports dtype of torch.bfloat16, torch.float16 currently.\n",
            "  warnings.warn(error_message)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[1] Prompt: Explain quantization in LLMs in one paragraph.\n",
            "\n",
            "Output:\n",
            "The quantization of a sentence is the number of words that are in the sentence, divided by the number\n",
            "of tokens in the input.\n",
            "For example, if we have a sentence like \"I love my dog\", then the quantization would be 1000.\n",
            "If we have 200 tokens, then the number would be: 2.\n",
            "This is because the quantized sentence has 2 tokens and 2 words.\n",
            "In this case, the quantizer would be the number 2, which is 2 t...\n",
            "\n",
            "Metrics:\n",
            "  Latency:         20.95 s\n",
            "  Peak GPU Memory: 0.00 MB\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "[2] Prompt: Write a short description of Scooby-Doo and the Mystery Inc. gang.\n",
            "\n",
            "Output:\n",
            "Scooby is a fictional character created by author Dr. Seuss. He is a mischievous boy who loves to play pranks on his friends. One day, he meets a group of kids called the Mystery Inns, who are trying to solve a mystery involving a mysterious creature. Scoob is one of the kids in the Mystery Inn gang, and he has been invited to join the group.\n",
            "```\n",
            "```python\n",
            "```\n",
            "\n",
            "Metrics:\n",
            "  Latency:         7.45 s\n",
            "  Peak GPU Memory: 0.00 MB\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "[3] Prompt: Explain the process of photosynthesis in one paragraph.\n",
            "\n",
            "Output:\n",
            "The process of Photosynthesis is a complex and fascinating phenomenon that occurs in plants, algae, and some bacteria. It involves the use of light energy from the sun to convert carbon dioxide and water into glucose (a type of sugar) and oxygen. This process is essential for the growth and survival of all living organisms on Earth.\n",
            "```python\n",
            "# Explain the process\n",
            "\n",
            "# Write a paragraph explaining t...\n",
            "\n",
            "Metrics:\n",
            "  Latency:         6.94 s\n",
            "  Peak GPU Memory: 0.00 MB\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "Averages:\n",
            "  Avg Latency:     11.78 s\n",
            "  Avg Peak GPU MB: 0.00 MB\n"
          ]
        }
      ],
      "source": [
        "# Part 2.2: Evaluation on multiple prompts\n",
        "# ======================================================\n",
        "# Run a few prompts\n",
        "# ======================================================\n",
        "prompts = [\n",
        "    \"Explain quantization in LLMs in one paragraph.\",\n",
        "    \"Write a short description of Scooby-Doo and the Mystery Inc. gang.\",\n",
        "    \"Explain the process of photosynthesis in one paragraph.\"\n",
        "]\n",
        "results = [run_prompt(p) for p in prompts]\n",
        "\n",
        "# ======================================================\n",
        "# Print Results\n",
        "# ======================================================\n",
        "lat_list, mem_list = [], []\n",
        "for i, r in enumerate(results, 1):\n",
        "    lat_list.append(r[\"latency_s\"])\n",
        "    mem_list.append(r[\"gpu_mem_MB\"])\n",
        "    print(f\"\\n[{i}] Prompt: {r['prompt']}\\n\")\n",
        "    print(\"Output:\")\n",
        "    print(r[\"output\"][:400] + (\"...\" if len(r[\"output\"]) > 400 else \"\"))\n",
        "    print(\"\\nMetrics:\")\n",
        "    print(f\"  Latency:         {r['latency_s']:.2f} s\")\n",
        "    print(f\"  Peak GPU Memory: {r['gpu_mem_MB']:.2f} MB\")\n",
        "    print(\"-\"*78)\n",
        "\n",
        "# --- Averages ---\n",
        "import math\n",
        "def avg(x): return (sum(x)/len(x)) if x else math.nan\n",
        "print(\"\\nAverages:\")\n",
        "print(f\"  Avg Latency:     {avg(lat_list):.2f} s\")\n",
        "print(f\"  Avg Peak GPU MB: {avg(mem_list):.2f} MB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34868930-cd4e-4cc6-9073-ef2ceebdddd6",
      "metadata": {
        "id": "34868930-cd4e-4cc6-9073-ef2ceebdddd6"
      },
      "source": [
        "### Part 2.3: Results\n",
        "The SmolLM-135M base model was evaluated on three distinct prompts to measure both generation quality and performance metrics such as latency and GPU memory usage. Note that all of my tests were conducted on CPU, resulting in higher latency values and 0 MB GPU memory utilization.\n",
        "\n",
        "Overall, the SmolLM-135M model produced intelligible but inconsistent and partially incorrect outputs across topics. The average latency on CPU was around 20 seconds per max 250-token generation. Using an instruction-tuned variant or a GPU environment would likely yield both higher-quality responses and significantly improved runtime performance. More varied prompts to text realms like coding, math, text revision, etc. would better evaluate the model across a wider range of tasks, as the current prompts mainly test explanation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e06a83ae-0a07-4c27-b1d9-4ff17a3a6d2f",
      "metadata": {
        "id": "e06a83ae-0a07-4c27-b1d9-4ff17a3a6d2f"
      },
      "source": [
        "## Part 3: Implement Weight Quantization (8-bit vs 4-bit)\n",
        "*Use AutoAWQ or bitsandbytes to quantize the model weights. Compare latency, memory usage, and output accuracy for both versions.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a48a3110",
      "metadata": {
        "id": "a48a3110",
        "outputId": "47458430-1993-4501-bbc2-b30e5dea5801"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: CUDA  |  Precision: torch.float16\n"
          ]
        }
      ],
      "source": [
        "# Part 3.1: SmolLM-135M model and bitsandbytes quantization\n",
        "import time, torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Pick device/precision (CUDA if available)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "dtype  = torch.float16 if device == \"cuda\" else torch.float32\n",
        "print(f\"Using device: {device.upper()}  |  Precision: {dtype}\")\n",
        "\n",
        "# Load model/tokenizer\n",
        "model_id = \"HuggingFaceTB/SmolLM-135M\"\n",
        "tok = AutoTokenizer.from_pretrained(model_id)\n",
        "if tok.pad_token is None:\n",
        "    tok.pad_token = tok.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    dtype=dtype,\n",
        "    device_map=\"auto\" if device == \"cuda\" else None\n",
        ").to(device).eval()\n",
        "\n",
        "def run_prompt(prompt, max_new_tokens=250):\n",
        "    \"\"\"Generate text and measure latency, throughput, and peak GPU memory.\"\"\"\n",
        "    wrapped = f\"### Instruction:\\n{prompt}\\n\\n### Response:\\n\"\n",
        "    inputs = tok(wrapped, return_tensors=\"pt\").to(device)\n",
        "    input_len = inputs[\"input_ids\"].shape[-1]\n",
        "\n",
        "    if device == \"cuda\":\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "    t0 = time.perf_counter()\n",
        "    with torch.inference_mode(), torch.autocast(device_type=device, dtype=dtype):\n",
        "        out = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=False, temperature=1.0, top_p=1.0,\n",
        "            no_repeat_ngram_size=3, repetition_penalty=1.05,\n",
        "            pad_token_id=tok.pad_token_id, eos_token_id=tok.eos_token_id\n",
        "        )\n",
        "    dt = time.perf_counter() - t0\n",
        "\n",
        "    # Decode only new tokens (avoid echoing the prompt)\n",
        "    new_tokens = out[0][input_len:]\n",
        "    text = tok.decode(new_tokens, skip_special_tokens=True).strip()\n",
        "\n",
        "    gen_tokens = int(new_tokens.shape[0])\n",
        "    mem_mb = torch.cuda.max_memory_allocated() / (1024**2) if device == \"cuda\" else 0.0\n",
        "\n",
        "    return {\"prompt\": prompt, \"latency_s\": dt, \"gpu_mem_MB\": mem_mb, \"output\": text}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddb9e9a5",
      "metadata": {
        "id": "ddb9e9a5",
        "outputId": "53cc55f4-85ee-406e-d732-15a0eba48154"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading tokenizer...\n",
            "Loading base model (FP16)...\n",
            "Base model: 791.5 MB\n",
            "Loading 8-bit model...\n",
            "8-bit model: 791.5 MB\n",
            "Loading 4-bit model...\n",
            "4-bit model: 848.5 MB\n"
          ]
        }
      ],
      "source": [
        "# Part 3.2: Load Base Model and Quantized Models\n",
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "# Load tokenizer\n",
        "print(\"Loading tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Load base model (FP16)\n",
        "print(\"Loading base model (FP16)...\")\n",
        "clear_memory()\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id, torch_dtype=torch.float16, device_map=\"auto\"\n",
        ").eval()\n",
        "base_memory = get_memory()\n",
        "print(f\"Base model: {base_memory:.1f} MB\")\n",
        "\n",
        "# Load 8-bit model\n",
        "print(\"Loading 8-bit model...\")\n",
        "clear_memory()\n",
        "bnb_8bit = BitsAndBytesConfig(load_in_8bit=True)\n",
        "model_8bit = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id, quantization_config=bnb_8bit, device_map=\"auto\"\n",
        ").eval()\n",
        "memory_8bit = get_memory()\n",
        "print(f\"8-bit model: {memory_8bit:.1f} MB\")\n",
        "\n",
        "# Load 4-bit model\n",
        "print(\"Loading 4-bit model...\")\n",
        "clear_memory()\n",
        "bnb_4bit = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_quant_type=\"nf4\")\n",
        "model_4bit = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id, quantization_config=bnb_4bit, device_map=\"auto\"\n",
        ").eval()\n",
        "memory_4bit = get_memory()\n",
        "print(f\"4-bit model: {memory_4bit:.1f} MB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de0531ed",
      "metadata": {
        "id": "de0531ed",
        "outputId": "60490ef7-5fe8-4aab-8e32-126234e0bfe4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing all models...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Base model latency: 0.591s\n",
            "8-bit model latency: 2.069s\n",
            "4-bit model latency: 0.881s\n"
          ]
        }
      ],
      "source": [
        "# Part 3.3: Test All Models\n",
        "def measure_latency(model, prompt=\"What is AI?\"):\n",
        "    inputs = tokenizer(f\"### Instruction:\\n{prompt}\\n\\n### Response:\\n\", return_tensors=\"pt\").to(device)\n",
        "\n",
        "    start = time.perf_counter()\n",
        "    with torch.inference_mode():\n",
        "        model.generate(**inputs, max_new_tokens=30, do_sample=False)\n",
        "    return time.perf_counter() - start\n",
        "\n",
        "# Test all models\n",
        "print(\"Testing all models...\")\n",
        "base_latency = measure_latency(base_model)\n",
        "latency_8bit = measure_latency(model_8bit)\n",
        "latency_4bit = measure_latency(model_4bit)\n",
        "\n",
        "print(f\"Base model latency: {base_latency:.3f}s\")\n",
        "print(f\"8-bit model latency: {latency_8bit:.3f}s\")\n",
        "print(f\"4-bit model latency: {latency_4bit:.3f}s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e143b2e7",
      "metadata": {
        "id": "e143b2e7",
        "outputId": "cd9bfed8-cdf1-46e9-abee-e44408962c94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QUANTIZATION COMPARISON RESULTS\n",
            "==================================================\n",
            "\n",
            "Memory Usage:\n",
            "Base Model (FP16):  791.5 MB\n",
            "8-bit Quantized:    791.5 MB\n",
            "4-bit Quantized:    848.5 MB\n",
            "\n",
            "Latency:\n",
            "Base Model:         0.591s\n",
            "8-bit Model:        2.069s\n",
            "4-bit Model:        0.881s\n",
            "\n",
            "Memory Usage Change:\n",
            "8-bit: 0.0% reduction\n",
            "4-bit: 7.2% increase\n",
            "\n",
            "Speed Comparison:\n",
            "8-bit is 3.50x slower\n",
            "4-bit is 1.49x slower\n",
            "\n",
            "Quantization successfully implemented and tested.\n"
          ]
        }
      ],
      "source": [
        "# Part 3.4: Quantization Comparison Results\n",
        "print(\"QUANTIZATION COMPARISON RESULTS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(f\"\\nMemory Usage:\")\n",
        "print(f\"Base Model (FP16):  {base_memory:.1f} MB\")\n",
        "print(f\"8-bit Quantized:    {memory_8bit:.1f} MB\")\n",
        "print(f\"4-bit Quantized:    {memory_4bit:.1f} MB\")\n",
        "\n",
        "print(f\"\\nLatency:\")\n",
        "print(f\"Base Model:         {base_latency:.3f}s\")\n",
        "print(f\"8-bit Model:        {latency_8bit:.3f}s\")\n",
        "print(f\"4-bit Model:        {latency_4bit:.3f}s\")\n",
        "\n",
        "# Calculate memory differences\n",
        "mem_change_8bit = ((memory_8bit - base_memory) / base_memory) * 100\n",
        "mem_change_4bit = ((memory_4bit - base_memory) / base_memory) * 100\n",
        "\n",
        "print(f\"\\nMemory Usage Change:\")\n",
        "if mem_change_8bit > 0:\n",
        "    print(f\"8-bit: {mem_change_8bit:.1f}% increase\")\n",
        "elif mem_change_8bit < 0:\n",
        "    print(f\"8-bit: {abs(mem_change_8bit):.1f}% reduction\")\n",
        "else:\n",
        "    print(f\"8-bit: No change\")\n",
        "\n",
        "if mem_change_4bit > 0:\n",
        "    print(f\"4-bit: {mem_change_4bit:.1f}% increase\")\n",
        "elif mem_change_4bit < 0:\n",
        "    print(f\"4-bit: {abs(mem_change_4bit):.1f}% reduction\")\n",
        "else:\n",
        "    print(f\"4-bit: No change\")\n",
        "\n",
        "print(f\"\\nSpeed Comparison:\")\n",
        "if latency_8bit < base_latency:\n",
        "    print(f\"8-bit is {base_latency/latency_8bit:.2f}x faster\")\n",
        "else:\n",
        "    print(f\"8-bit is {latency_8bit/base_latency:.2f}x slower\")\n",
        "\n",
        "if latency_4bit < base_latency:\n",
        "    print(f\"4-bit is {base_latency/latency_4bit:.2f}x faster\")\n",
        "else:\n",
        "    print(f\"4-bit is {latency_4bit/base_latency:.2f}x slower\")\n",
        "\n",
        "print(f\"\\nQuantization successfully implemented and tested.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b46ac54c",
      "metadata": {
        "id": "b46ac54c"
      },
      "source": [
        "When running the quanitzation it should use both less gpu memory and decrease the latency. Due to the model being small and running on a gpu that supports FP16, this is not the case. When running on CPU, quantization should help out by both reducing memory and latency."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b8aa6a1-1dd8-4bd9-aced-580b5917f60a",
      "metadata": {
        "id": "4b8aa6a1-1dd8-4bd9-aced-580b5917f60a"
      },
      "source": [
        "## Part 4: Implement Static KV-Cache Quantization\n",
        "*Quantize the model’s KV cache at a fixed bit-width (e.g., 4 bits). Measure the impact on inference speed, memory consumption, and accuracy.*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade pip\n",
        "!pip install -q --upgrade transformers accelerate optimum-quanto\n",
        "!pip install -q ninja \"transformers>=4.45\" accelerate \"optimum-quanto>=0.2.3\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vypq_HADMxb3",
        "outputId": "792de67b-b724-4169-b1ed-47cf8bf168ac"
      },
      "id": "Vypq_HADMxb3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\anthony\\anaconda3\\envs\\kvq\\lib\\site-packages)\n",
            "ERROR: To modify pip, please run the following command:\n",
            "C:\\Users\\Anthony\\anaconda3\\envs\\kvq\\python.exe -m pip install -q --upgrade pip\n",
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\anthony\\anaconda3\\envs\\kvq\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\anthony\\anaconda3\\envs\\kvq\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\anthony\\anaconda3\\envs\\kvq\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\anthony\\anaconda3\\envs\\kvq\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\anthony\\anaconda3\\envs\\kvq\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\anthony\\anaconda3\\envs\\kvq\\lib\\site-packages)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.utils import is_optimum_quanto_available\n",
        "print(\"optimum-quanto available?\", is_optimum_quanto_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdOM6XLEM-GN",
        "outputId": "9d12b8f1-cc10-4146-a0e3-c09ee32c3f78"
      },
      "id": "pdOM6XLEM-GN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "optimum-quanto available? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "# 1) Make sure you have the CUDA build of PyTorch in THIS kernel\n",
        "!{sys.executable} -m pip uninstall -y torch torchvision torchaudio\n",
        "!{sys.executable} -m pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "# 2) Verify CUDA is available\n",
        "import torch\n",
        "print(\"cuda available:\", torch.cuda.is_available())\n",
        "print(\"torch:\", torch.__version__, \"| torch cuda:\", torch.version.cuda)\n",
        "if torch.cuda.is_available():\n",
        "    print(\"gpu:\", torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6d4UfkKWTbI",
        "outputId": "4acbaa79-e27f-4b19-bdf9-88bcf054f151"
      },
      "id": "e6d4UfkKWTbI",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.5.1\n",
            "Uninstalling torch-2.5.1:\n",
            "  Successfully uninstalled torch-2.5.1\n",
            "Found existing installation: torchvision 0.20.1+cu121\n",
            "Uninstalling torchvision-0.20.1+cu121:\n",
            "  Successfully uninstalled torchvision-0.20.1+cu121\n",
            "Found existing installation: torchaudio 2.5.1+cu121\n",
            "Uninstalling torchaudio-2.5.1+cu121:\n",
            "  Successfully uninstalled torchaudio-2.5.1+cu121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\anthony\\anaconda3\\envs\\kvq\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\anthony\\anaconda3\\envs\\kvq\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -orch (c:\\users\\anthony\\anaconda3\\envs\\kvq\\lib\\site-packages)\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "optimum-quanto 0.2.7 requires torch>=2.6.0, but you have torch 2.5.1+cu121 which is incompatible.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in c:\\users\\anthony\\anaconda3\\envs\\kvq\\lib\\site-packages (2.9.0)\n",
            "Collecting torchvision\n",
            "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp310-cp310-win_amd64.whl (6.1 MB)\n",
            "Collecting torchaudio\n",
            "  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp310-cp310-win_amd64.whl (4.1 MB)\n",
            "Requirement already satisfied: filelock in c:\\users\\anthony\\anaconda3\\envs\\kvq\\lib\\site-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\anthony\\anaconda3\\envs\\kvq\\lib\\site-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\anthony\\anaconda3\\envs\\kvq\\lib\\site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\anthony\\anaconda3\\envs\\kvq\\lib\\site-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\anthony\\anaconda3\\envs\\kvq\\lib\\site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\anthony\\anaconda3\\envs\\kvq\\lib\\site-packages (from torch) (2025.9.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\anthony\\anaconda3\\envs\\kvq\\lib\\site-packages (from torchvision) (2.1.2)\n",
            "Collecting torch\n",
            "  Using cached https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp310-cp310-win_amd64.whl (2449.4 MB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\anthony\\anaconda3\\envs\\kvq\\lib\\site-packages (from torchvision) (11.3.0)\n",
            "Collecting sympy==1.13.1 (from torch)\n",
            "  Using cached https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\anthony\\anaconda3\\envs\\kvq\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\anthony\\anaconda3\\envs\\kvq\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
            "Installing collected packages: sympy, torch, torchvision, torchaudio\n",
            "\n",
            "  Attempting uninstall: sympy\n",
            "\n",
            "    Found existing installation: sympy 1.14.0\n",
            "\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "    Uninstalling sympy-1.14.0:\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "      Successfully uninstalled sympy-1.14.0\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "  Attempting uninstall: torch\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "    Found existing installation: torch 2.9.0\n",
            "   ---------------------------------------- 0/4 [sympy]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "    Uninstalling torch-2.9.0:\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "      Successfully uninstalled torch-2.9.0\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   ---------- ----------------------------- 1/4 [torch]\n",
            "   -------------------- ------------------- 2/4 [torchvision]\n",
            "   -------------------- ------------------- 2/4 [torchvision]\n",
            "   -------------------- ------------------- 2/4 [torchvision]\n",
            "   -------------------- ------------------- 2/4 [torchvision]\n",
            "   -------------------- ------------------- 2/4 [torchvision]\n",
            "   -------------------- ------------------- 2/4 [torchvision]\n",
            "   -------------------- ------------------- 2/4 [torchvision]\n",
            "   ------------------------------ --------- 3/4 [torchaudio]\n",
            "   ------------------------------ --------- 3/4 [torchaudio]\n",
            "   ------------------------------ --------- 3/4 [torchaudio]\n",
            "   ---------------------------------------- 4/4 [torchaudio]\n",
            "\n",
            "Successfully installed sympy-1.13.1 torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121\n",
            "cuda available: True\n",
            "torch: 2.5.1+cu121 | torch cuda: 12.1\n",
            "gpu: NVIDIA GeForce RTX 3090\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.version.cuda)\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "id": "7DncynvuPDB6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7598826a-fc3e-4099-b105-c9e5a71afb2b"
      },
      "id": "7DncynvuPDB6",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12.1\n",
            "True\n",
            "NVIDIA GeForce RTX 3090\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time, math, os, psutil, torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from transformers.utils import is_optimum_quanto_available\n",
        "assert torch.cuda.is_available(), \"CUDA GPU required\" #Hard cuda requirement for part 4\n",
        "\n",
        "#--------------------------------\n",
        "#Config\n",
        "#--------------------------------\n",
        "\n",
        "ModelID = \"HuggingFaceTB/SmolLM-135M\"\n",
        "prompts = [\n",
        "    \"Explain quantization in LLMs in one paragraph.\",\n",
        "    \"Write a short description of Scooby-Doo and the Mystery Inc. gang.\",\n",
        "    \"Explain the process of photosynthesis in one paragraph.\"\n",
        "]\n",
        "\n",
        "#pick device, not really necessary because of CUDA requirement, but cpu can still run, just wont be given a memory value\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device:\", device.type)\n",
        "\n",
        "dataType = torch.float16 if device.type == \"cuda\" else torch.float32\n",
        "print(f\"Using precision: {dataType}\")\n",
        "\n",
        "#toeknizer model recycled\n",
        "tokenizer = AutoTokenizer.from_pretrained(ModelID)\n",
        "if tokenizer.pad_token_id is None:\n",
        "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(ModelID, dtype=dataType).to(device).eval()\n",
        "USE_KVQ = is_optimum_quanto_available()\n",
        "KVQ_CFG = {\"backend\": \"quanto\", \"nbits\": 4} #configure KV cache 4 bit (INT4) via \"quanto\" backend\n",
        "print(\"Use KVQ:\", USE_KVQ)\n",
        "#---------------------------\n",
        "#Core Measurement\n",
        "#---------------------------\n",
        "\n",
        "def runOnce(prompt, max_new_tokens = 1024, kv_quant = False): #core measurement function\n",
        "  inputs = tokenizer(prompt, return_tensors=\"pt\").to(device) #tokenize and transfer to GPU\n",
        "  if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache() #Reset cuda memory stats\n",
        "    torch.cuda.reset_peak_memory_stats()\n",
        "    torch.cuda.synchronize()\n",
        "    memBefore = torch.cuda.max_memory_allocated() / (1024 ** 2) #capture memory before generation\n",
        "\n",
        "  gen_kwargs = {}\n",
        "\n",
        "\n",
        "  if kv_quant and USE_KVQ:\n",
        "    gen_kwargs.update(dict(cache_implementation=\"quantized\", cache_config=KVQ_CFG)) #warmup for when KVQ is enabled\n",
        "\n",
        "\n",
        "  if kv_quant and USE_KVQ and not getattr(runOnce, \"_warmed\", False):\n",
        "      _ = model.generate(**inputs, max_new_tokens=1, do_sample=False, **gen_kwargs)\n",
        "      torch.cuda.synchronize()\n",
        "      runOnce._warmed = True\n",
        "      torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "\n",
        "  #--------------------------\n",
        "  #Timed Gen\n",
        "  #--------------------------\n",
        "  t0 = time.perf_counter()\n",
        "\n",
        "  out = model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens=max_new_tokens,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        "    return_dict_in_generate=True,\n",
        "    output_scores=True,\n",
        "    do_sample=False,\n",
        "    **gen_kwargs\n",
        "  )\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "  dt = time.perf_counter() - t0\n",
        "\n",
        "  peak = torch.cuda.max_memory_allocated() / (1024 ** 2) #peak VRAM\n",
        "  kv_delta = max(0.0, peak - memBefore) #Estimate KV cache footprint\n",
        "\n",
        "  new_ids = out.sequences[:, inputs.input_ids.shape[1]:]\n",
        "  text = tokenizer.batch_decode(new_ids, skip_special_tokens=True)[0][:200] + \"...\"\n",
        "\n",
        "  mem_mb = (torch.cuda.max_memory_allocated() / (1024 ** 2)) if device.type == \"cuda\" else 0.0\n",
        "  return {'latency_s': dt, \"peak_MB\": peak, \"mem\": mem_mb, \"kv_MB\": kv_delta, \"text\": text, \"kv_quant\": bool(kv_quant) and USE_KVQ}\n",
        "\n",
        "\n",
        "base = (\"This is a natural paragraph about language models and token generation. \") * 120\n",
        "\n",
        "long_prompt = base + \"\\n\\nContinue with a consise summary\"\n",
        "short_prompt = base + \"\\n\\nExplain quantization in LLMs in one paragraph.\"\n",
        "\n",
        "\n",
        "short_baseline_Run = runOnce(short_prompt, max_new_tokens=128, kv_quant=False)\n",
        "short_kvq = runOnce(short_prompt, max_new_tokens=128, kv_quant=True)\n",
        "\n",
        "long_baseline_Run = runOnce(long_prompt, max_new_tokens=512, kv_quant=False)\n",
        "long_kvq = runOnce(long_prompt, max_new_tokens=512, kv_quant=True)\n",
        "\n",
        "print(\"Baseline Long:\", long_baseline_Run)\n",
        "print(\"KV-INT4 Long:\", long_kvq)\n",
        "print(\"Baseline Short:\", short_baseline_Run)\n",
        "print(\"KV-INT4 Short:\", short_kvq)\n",
        "\n",
        "if long_baseline_Run[\"kv_MB\"] > 0:\n",
        "  savings = long_baseline_Run[\"kv_MB\"] - long_kvq[\"kv_MB\"]\n",
        "  savingsPCT = 100.0 * savings/long_baseline_Run[\"kv_MB\"]\n",
        "  print(f\"KV delta: {long_baseline_Run['kv_MB']:.1f}MB | with INT4: {long_kvq['kv_MB']:.1f}MB\")\n",
        "  print(f\"KV savings: {savings:.1f} MB ({savingsPCT:.1f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTrblGZoNCHr",
        "outputId": "b80c3df5-3a50-4fcd-cd23-277ab0f3970a"
      },
      "id": "MTrblGZoNCHr",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Using precision: torch.float16\n",
            "Use KVQ: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Long: {'latency_s': 26.75394090000009, 'peak_MB': 560.96826171875, 'mem': 560.96826171875, 'kv_MB': 296.23095703125, 'text': ' of the article.\\n\\nThis is a natural paragraph about the article.\\n\\nThis is a natural paragraph about the article.\\n\\nThis is a natural paragraph about the article.\\n\\nThis is a natural paragraph about the ...', 'kv_quant': False}\n",
            "KV-INT4 Long: {'latency_s': 35.6673008000007, 'peak_MB': 539.37255859375, 'mem': 539.37255859375, 'kv_MB': 274.63525390625, 'text': ' of the article.\\n\\nThis is a natural paragraph about the article.\\n\\nThis is a natural paragraph about the article.\\n\\nThis is a natural paragraph about the article.\\n\\nThis is a natural paragraph about the ...', 'kv_quant': True}\n",
            "Baseline Short: {'latency_s': 7.05027599999994, 'peak_MB': 562.35205078125, 'mem': 562.35205078125, 'kv_MB': 305.73974609375, 'text': '\\n\\nExplain quantization in LLMs in one paragraph.\\n\\nExplain quantization in LLMs in one paragraph.\\n\\nExplain quantization in LLMs in one paragraph.\\n\\nExplain quantization in LLMs in one paragraph.\\n\\nExplai...', 'kv_quant': False}\n",
            "KV-INT4 Short: {'latency_s': 9.314467999999579, 'peak_MB': 540.79736328125, 'mem': 540.79736328125, 'kv_MB': 276.06005859375, 'text': '\\n\\nExplain quantization in LLMs in one paragraph.\\n\\nExplain quantization in LLMs in one paragraph.\\n\\nExplain quantization in LLMs in one paragraph.\\n\\nExplain quantization in LLMs in one paragraph.\\n\\nExplai...', 'kv_quant': True}\n",
            "KV delta: 296.2MB | with INT4: 274.6MB\n",
            "KV savings: 21.6 MB (7.3%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_results_table(results, title=\"Results Table\"):\n",
        "    print(f\"\\n==== {title} ====\")\n",
        "    print(f\"{'Type':15s} | {'Latency (s)':12s} | {'KV Δ (MB)':10s} | {'Peak MB':10s} | {'KV Quant?':10s}\")\n",
        "    print(\"-\" * 70)\n",
        "    for name, r in results:\n",
        "        print(f\"{name:15s} | {r['latency_s']:<12.3f} | {r['kv_MB']:<10.1f} | {r['peak_MB']:<10.1f} | {str(r['kv_quant']):10s}\")\n",
        "\n",
        "results = [\n",
        "    (\"Short Base\", short_baseline_Run),\n",
        "    (\"Short KVQ\", short_kvq),\n",
        "    (\"Long Base\", long_baseline_Run),\n",
        "    (\"Long KVQ\", long_kvq),\n",
        "]\n",
        "\n",
        "print_results_table(results, title=\"KV Cache Quantization Results\")\n",
        "\n",
        "if long_baseline_Run[\"kv_MB\"] > 0:\n",
        "    savings = long_baseline_Run[\"kv_MB\"] - long_kvq[\"kv_MB\"]\n",
        "    savingsPCT = 100.0 * savings / long_baseline_Run[\"kv_MB\"]\n",
        "    print(f\"\\nKV Savings (Long Prompt): {savings:.2f} MB ({savingsPCT:.2f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Alz7Xxd0XYi7",
        "outputId": "070a9e83-717b-4e19-cc54-7bd5bd9761e4"
      },
      "id": "Alz7Xxd0XYi7",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==== KV Cache Quantization Results ====\n",
            "Type            | Latency (s)  | KV Δ (MB)  | Peak MB    | KV Quant? \n",
            "----------------------------------------------------------------------\n",
            "Short Base      | 7.050        | 305.7      | 562.4      | False     \n",
            "Short KVQ       | 9.314        | 276.1      | 540.8      | True      \n",
            "Long Base       | 26.754       | 296.2      | 561.0      | False     \n",
            "Long KVQ        | 35.667       | 274.6      | 539.4      | True      \n",
            "\n",
            "KV Savings (Long Prompt): 21.60 MB (7.29%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The findings from part 4 compares the baseline Floating Point 16 generation vs KV-Cache INT4 quantization on the same prompts.\n",
        "\n",
        "The Key Fields Measured:\n",
        "\n",
        "- Latency: Decode Time\n",
        "- Peak: peak GPU memory during generation\n",
        "- KV MB: Estimated KV-Cache footprint\n",
        "- KV Quant: Activated or Deactivated upon request"
      ],
      "metadata": {
        "id": "84L0ObFpXenN"
      },
      "id": "84L0ObFpXenN"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "33c2fda358f940da93d88054b050229e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c818f2a9ea7d490bbd4deac8c45f3e14",
              "IPY_MODEL_93ded89c39864ba1aee151f1d13aa14e",
              "IPY_MODEL_8cb25e903f3d4f9faa6fbad6508bf2bb"
            ],
            "layout": "IPY_MODEL_fd3844fbb4b24cd0b3a41b506363df16"
          }
        },
        "c818f2a9ea7d490bbd4deac8c45f3e14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ab46436215f412682dc286471340d1d",
            "placeholder": "​",
            "style": "IPY_MODEL_605463e55d734c74a3c23fe8e07adf0c",
            "value": "tokenizer_config.json: "
          }
        },
        "93ded89c39864ba1aee151f1d13aa14e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8f5178d331d464b89dbd47c1206b269",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83b1edbd137b4d41906c899c82d8a4a2",
            "value": 1
          }
        },
        "8cb25e903f3d4f9faa6fbad6508bf2bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7116fdc3ab034b509d7025caac2f7b2e",
            "placeholder": "​",
            "style": "IPY_MODEL_3dce19f827164711a6e3050327ccf034",
            "value": " 3.69k/? [00:00&lt;00:00, 243kB/s]"
          }
        },
        "fd3844fbb4b24cd0b3a41b506363df16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ab46436215f412682dc286471340d1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "605463e55d734c74a3c23fe8e07adf0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8f5178d331d464b89dbd47c1206b269": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "83b1edbd137b4d41906c899c82d8a4a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7116fdc3ab034b509d7025caac2f7b2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dce19f827164711a6e3050327ccf034": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c716ad721134481083b8f50c1332e16d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc0346dabc404d30b3d3009c2d04ade5",
              "IPY_MODEL_fdd492f29c97400f8c813c4869e6c4fb",
              "IPY_MODEL_ef208597411f4cd6bb98f573a40dd2ae"
            ],
            "layout": "IPY_MODEL_91b52e1fd9db468e8a30b79d33901182"
          }
        },
        "fc0346dabc404d30b3d3009c2d04ade5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_961a3e7931db488f97ea4bc997486446",
            "placeholder": "​",
            "style": "IPY_MODEL_e4c6d49bfa16453f944885705b8adc05",
            "value": "vocab.json: "
          }
        },
        "fdd492f29c97400f8c813c4869e6c4fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_538a566bfa8c4e2daf976014bcaa752a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd1d7de2b2cf41b5a2ea8456d9649c23",
            "value": 1
          }
        },
        "ef208597411f4cd6bb98f573a40dd2ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7910f05596b45f0ba943ff3ee1c93fd",
            "placeholder": "​",
            "style": "IPY_MODEL_c946a5bb81a44b198e337f382b5ada08",
            "value": " 801k/? [00:00&lt;00:00, 14.7MB/s]"
          }
        },
        "91b52e1fd9db468e8a30b79d33901182": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "961a3e7931db488f97ea4bc997486446": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4c6d49bfa16453f944885705b8adc05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "538a566bfa8c4e2daf976014bcaa752a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "cd1d7de2b2cf41b5a2ea8456d9649c23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7910f05596b45f0ba943ff3ee1c93fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c946a5bb81a44b198e337f382b5ada08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ac49eee029a4821bbcce494eb09a176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba04000c26a34a8c824d14e5f3aace00",
              "IPY_MODEL_596d40cbf4a84b2387b1ff03d54163da",
              "IPY_MODEL_71c2dca71979430299550e2585455269"
            ],
            "layout": "IPY_MODEL_7a10e21a6b7d4b35bde3f4986134dc41"
          }
        },
        "ba04000c26a34a8c824d14e5f3aace00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40cd95702f424061a5e538c4580b0a6f",
            "placeholder": "​",
            "style": "IPY_MODEL_90e2fdaa5e8344e2b4226d5e5a4cb779",
            "value": "merges.txt: "
          }
        },
        "596d40cbf4a84b2387b1ff03d54163da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_019ddcefd37743a69c00e288bf23980e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3bfc24a533a44760a746d3cc3b89a3aa",
            "value": 1
          }
        },
        "71c2dca71979430299550e2585455269": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b2ba83922e546bea7ad03139b7cee62",
            "placeholder": "​",
            "style": "IPY_MODEL_71b701308fcc4e669056c9cd8d1ef946",
            "value": " 466k/? [00:00&lt;00:00, 21.0MB/s]"
          }
        },
        "7a10e21a6b7d4b35bde3f4986134dc41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40cd95702f424061a5e538c4580b0a6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90e2fdaa5e8344e2b4226d5e5a4cb779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "019ddcefd37743a69c00e288bf23980e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "3bfc24a533a44760a746d3cc3b89a3aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b2ba83922e546bea7ad03139b7cee62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71b701308fcc4e669056c9cd8d1ef946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e9a53bf690546dc980b96f4e3428134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_251cf510a6c24ba89ba3c7555711c6da",
              "IPY_MODEL_261786f2049940b1ad008d8fe42522a1",
              "IPY_MODEL_784cda3ea692469d9ab5e87518fa5127"
            ],
            "layout": "IPY_MODEL_bd1c4ef5dd264564a7365e855345109c"
          }
        },
        "251cf510a6c24ba89ba3c7555711c6da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d837cc0ccb14df1a23d8c0ccf34a61f",
            "placeholder": "​",
            "style": "IPY_MODEL_ff06f2af132d4607a8694fd31116bac5",
            "value": "tokenizer.json: "
          }
        },
        "261786f2049940b1ad008d8fe42522a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_874709a5b447497391b98b5409be5cc6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f27fd94b7934cf89360e1b1d382a92b",
            "value": 1
          }
        },
        "784cda3ea692469d9ab5e87518fa5127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fb09718e8cf456aa2f6e4c631845d31",
            "placeholder": "​",
            "style": "IPY_MODEL_d58d20ca113f42be9f41a3ca421d237c",
            "value": " 2.10M/? [00:00&lt;00:00, 54.9MB/s]"
          }
        },
        "bd1c4ef5dd264564a7365e855345109c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d837cc0ccb14df1a23d8c0ccf34a61f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff06f2af132d4607a8694fd31116bac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "874709a5b447497391b98b5409be5cc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "3f27fd94b7934cf89360e1b1d382a92b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1fb09718e8cf456aa2f6e4c631845d31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d58d20ca113f42be9f41a3ca421d237c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d3be39910914222ae48435fa48fbc01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_933602ed7e734a688060efc101bdbf16",
              "IPY_MODEL_c67050aaae5d4a0fbe779f72b751ffba",
              "IPY_MODEL_efba7a3387a34d649d34e5a5fa58e862"
            ],
            "layout": "IPY_MODEL_ced04c569fe6488eb0d4f152503e6f67"
          }
        },
        "933602ed7e734a688060efc101bdbf16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09e66626b2574cad902cddb7f6bcbbaf",
            "placeholder": "​",
            "style": "IPY_MODEL_654d5a8cde724df6811e22c612010857",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "c67050aaae5d4a0fbe779f72b751ffba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da4976cdb7164fc9a88558bda86d9ac1",
            "max": 831,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20e216b0928741a79b5c436f84399aa2",
            "value": 831
          }
        },
        "efba7a3387a34d649d34e5a5fa58e862": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f16cc502637445db8d72bdab3c00195",
            "placeholder": "​",
            "style": "IPY_MODEL_ea20b7c4459c46a09e6151171187de83",
            "value": " 831/831 [00:00&lt;00:00, 89.5kB/s]"
          }
        },
        "ced04c569fe6488eb0d4f152503e6f67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09e66626b2574cad902cddb7f6bcbbaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "654d5a8cde724df6811e22c612010857": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da4976cdb7164fc9a88558bda86d9ac1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20e216b0928741a79b5c436f84399aa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f16cc502637445db8d72bdab3c00195": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea20b7c4459c46a09e6151171187de83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9cfaac283744dfc8352be879fe37d97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33cb5befbd534f8abf75183dc98a6b29",
              "IPY_MODEL_5cd9e4ff39174bc482c72b9c76fe2a01",
              "IPY_MODEL_b092c0351e714934844010f481dd36ef"
            ],
            "layout": "IPY_MODEL_f4473922d7b9410eb70e1dbf1271332e"
          }
        },
        "33cb5befbd534f8abf75183dc98a6b29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_848dd186be934a3ead1c2759bcc86dc0",
            "placeholder": "​",
            "style": "IPY_MODEL_ce0cf19bf802409a8ce5ca9af7808f58",
            "value": "config.json: 100%"
          }
        },
        "5cd9e4ff39174bc482c72b9c76fe2a01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7c30d6c78064751a8ec3347cb46135c",
            "max": 724,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_896de32bbcd24330b470f5658fd406d0",
            "value": 724
          }
        },
        "b092c0351e714934844010f481dd36ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7fcc364a8cf4d8e95eb555568e23383",
            "placeholder": "​",
            "style": "IPY_MODEL_56f4d77645fe4e69a0720941fc07d297",
            "value": " 724/724 [00:00&lt;00:00, 76.2kB/s]"
          }
        },
        "f4473922d7b9410eb70e1dbf1271332e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "848dd186be934a3ead1c2759bcc86dc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce0cf19bf802409a8ce5ca9af7808f58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7c30d6c78064751a8ec3347cb46135c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "896de32bbcd24330b470f5658fd406d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7fcc364a8cf4d8e95eb555568e23383": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56f4d77645fe4e69a0720941fc07d297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e9e86d786d7484daf6a4bb10315d023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_868fa306ad8b4f5387e92bf17811eb58",
              "IPY_MODEL_bdbe33baaf7b479cb7f78774810e7094",
              "IPY_MODEL_cf95a4b6ebce4489997fbed8aaa6ab68"
            ],
            "layout": "IPY_MODEL_f6a351d66a3c4ca1be83e0b66aac78d6"
          }
        },
        "868fa306ad8b4f5387e92bf17811eb58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6ed7d00f1b44fb790e58241d0f890c2",
            "placeholder": "​",
            "style": "IPY_MODEL_d53dcb7d9c3d40fc9385c90c3b5be62f",
            "value": "model.safetensors: 100%"
          }
        },
        "bdbe33baaf7b479cb7f78774810e7094": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ced5acc9df5425c986cc2084edc7782",
            "max": 538090408,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f23081972984776a6ab15c4595d0a16",
            "value": 538090408
          }
        },
        "cf95a4b6ebce4489997fbed8aaa6ab68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_911a11cde9ab4b91af602ad33db801b7",
            "placeholder": "​",
            "style": "IPY_MODEL_3b30e3b26a8740acba2ce1ecf4a20c3c",
            "value": " 538M/538M [00:08&lt;00:00, 102MB/s]"
          }
        },
        "f6a351d66a3c4ca1be83e0b66aac78d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6ed7d00f1b44fb790e58241d0f890c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d53dcb7d9c3d40fc9385c90c3b5be62f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ced5acc9df5425c986cc2084edc7782": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f23081972984776a6ab15c4595d0a16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "911a11cde9ab4b91af602ad33db801b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b30e3b26a8740acba2ce1ecf4a20c3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b898583b943d4e228cb9c5281ba1a4ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08a3d25dff1945e093f206694e800ad5",
              "IPY_MODEL_4ed66f2141f2483da331d73bbfb5a004",
              "IPY_MODEL_c4cd945d718b46e5bef5f0be29383096"
            ],
            "layout": "IPY_MODEL_c0abae17d8f74be3ba9c110434b96772"
          }
        },
        "08a3d25dff1945e093f206694e800ad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ef5814a2264472ea0f43a291da0abbe",
            "placeholder": "​",
            "style": "IPY_MODEL_9b70b2e9969c4cbbb484b33c068683df",
            "value": "generation_config.json: 100%"
          }
        },
        "4ed66f2141f2483da331d73bbfb5a004": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7890c2642a114f39aa028e2866262ee1",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7bfd0770a86b477a9029dbb17f3a15e1",
            "value": 111
          }
        },
        "c4cd945d718b46e5bef5f0be29383096": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_232746eab675492b9471407ebf17161d",
            "placeholder": "​",
            "style": "IPY_MODEL_c619e901ac524c038d5f6b344bd94b4c",
            "value": " 111/111 [00:00&lt;00:00, 3.29kB/s]"
          }
        },
        "c0abae17d8f74be3ba9c110434b96772": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ef5814a2264472ea0f43a291da0abbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b70b2e9969c4cbbb484b33c068683df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7890c2642a114f39aa028e2866262ee1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bfd0770a86b477a9029dbb17f3a15e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "232746eab675492b9471407ebf17161d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c619e901ac524c038d5f6b344bd94b4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}